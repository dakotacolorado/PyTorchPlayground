{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 2 Data Preprocessing\n",
    "**Objective:** Learn how data needs to be represented for machine learning algorithms to be applied."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from chinese_checkers.game.ChineseCheckersGame import ChineseCheckersGame\n",
    "from chinese_checkers.model.CentroidModel import CentroidModel\n",
    "from chinese_checkers.simulation.DataCatalog import DataCatalog\n",
    "from chinese_checkers.simulation.GameSimulation import GameSimulation\n",
    "from chinese_checkers.simulation.SimulationDataSet import SimulationDataSet\n",
    "\n",
    "from torch import tensor, zeros, save, stack, zeros_like\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T00:57:56.761306Z",
     "start_time": "2023-10-19T00:57:56.729895600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 State Representation\n",
    "\n",
    "To represent the `ChineseCheckersGame` state for PyTorch consumption, we must transform the board into a one-hot encoded vector. For a given position on the board, we'll represent each potential player's piece using a binary value: 1 if the player has a piece at that position and 0 otherwise.\n",
    "\n",
    "Given this, for a board of size `s` with `n` players, the length of our one-hot encoded state vector will be $s \\times n$.\n",
    "\n",
    "For clarity, the one-hot encoded representation is defined as:\n",
    "\n",
    "$$\n",
    "p_{i,j} =\n",
    "\\begin{cases}\n",
    "1 & \\ \\text{if player } j \\text{ has a piece at position } i,\\\\\n",
    "0 & \\ \\text{otherwise.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We'll begin by focusing on a board of size 4 with 2 players. Later, we can extend our approach to accommodate different board sizes and player counts.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "         0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "         0]])\n"
     ]
    }
   ],
   "source": [
    "def generate_tensor_for_game(game: ChineseCheckersGame) -> tensor:\n",
    "    all_positions = game.board.hexagram_points\n",
    "    encoded_state = tensor([\n",
    "        [\n",
    "            1 if position in player.positions else 0\n",
    "            for position in all_positions\n",
    "        ]\n",
    "        for player in game.players\n",
    "    ])\n",
    "\n",
    "    return encoded_state\n",
    "\n",
    "game = ChineseCheckersGame.start_game(number_of_players=2, board_size=4)\n",
    "game_state = generate_tensor_for_game(game)\n",
    "print(game_state)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T06:30:56.200557200Z",
     "start_time": "2023-10-18T06:30:56.187843200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n         0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n         0]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have added this as a method to the ChineseCheckersGame class\n",
    "game.tensor()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T06:30:56.213697900Z",
     "start_time": "2023-10-18T06:30:56.198555700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Encoding Sequence of Game States\n",
    "\n",
    "With the capability to encode individual game states, our next step is encoding sequences of game states that represent an entire game. To ensure consistency, we'll set a limit of 400 turns for each game. Each game state within this sequence will occupy a row in our matrix.\n",
    "\n",
    "In cases where a game concludes before reaching the 400-turn limit, we'll pad the matrix with rows of zeros until it reaches the desired size. This ensures that each game, regardless of its duration, results in a consistent-sized matrix which can be efficiently processed by PyTorch."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of turns: 287\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([400, 2, 121])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_tensor_for_game_sequence(game_sequence: List[ChineseCheckersGame], max_turns = 400):\n",
    "    game_sequence_tensors = [ game_state.tensor() for game_state in game_sequence ]\n",
    "\n",
    "    padding_size = max_turns - len(game_sequence)\n",
    "    if padding_size > 0:\n",
    "        padding = [zeros_like(game_sequence_tensors[0])] * padding_size\n",
    "        game_sequence_tensors.extend(padding)\n",
    "\n",
    "    return stack(game_sequence_tensors)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "simulation = GameSimulation([CentroidModel(), CentroidModel()], max_turns=400)\n",
    "simulation.simulate_game()\n",
    "print(f\"No. of turns: {len(simulation.games)}\")\n",
    "\n",
    "game_sequence_tensor = generate_tensor_for_game_sequence(simulation.games, simulation.max_turns)\n",
    "game_sequence_tensor.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T06:37:37.385470800Z",
     "start_time": "2023-10-18T06:37:36.166768800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([400, 2, 121])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have added this as a method to the GameSimulation class\n",
    "simulation.tensor(400).size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T06:37:39.264760400Z",
     "start_time": "2023-10-18T06:37:39.165704100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 Generating Data for Training\n",
    "Run a lot of naive simulations and save the results to a file. This will be our training data to bootstrap the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data for version: 0000\n",
      "Draws: 351\n",
      "Player 0 wins: 498 (49.8%)\n",
      "Player 1 wins: 502 (50.2%)\n",
      "Saving dataset: 0000\n",
      "Generating data for version: 0001\n",
      "Draws: 310\n",
      "Player 0 wins: 504 (50.4%)\n",
      "Player 1 wins: 496 (49.6%)\n",
      "Saving dataset: 0001\n",
      "Generating data for version: 0002\n",
      "Draws: 317\n",
      "Player 0 wins: 499 (49.9%)\n",
      "Player 1 wins: 501 (50.1%)\n",
      "Saving dataset: 0002\n",
      "Generating data for version: 0003\n",
      "Draws: 322\n",
      "Player 0 wins: 507 (50.7%)\n",
      "Player 1 wins: 493 (49.3%)\n",
      "Saving dataset: 0003\n",
      "Generating data for version: 0004\n",
      "Draws: 314\n",
      "Player 0 wins: 496 (49.6%)\n",
      "Player 1 wins: 504 (50.4%)\n",
      "Saving dataset: 0004\n",
      "Generating data for version: 0005\n",
      "Draws: 301\n",
      "Player 0 wins: 483 (48.3%)\n",
      "Player 1 wins: 517 (51.7%)\n",
      "Saving dataset: 0005\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't decrement id ref count (unable to extend file properly)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "File \u001B[1;32mc:\\users\\dakot\\workplace\\pytorchplayground\\venv\\src\\chinese-checkers\\src\\chinese_checkers\\simulation\\DataCatalog.py:58\u001B[0m, in \u001B[0;36mDataCatalog.save_dataset\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m h5py\u001B[38;5;241m.\u001B[39mFile(dataset_path \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mFILENAME, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m h5file:\n\u001B[1;32m---> 58\u001B[0m     \u001B[43mh5file\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     59\u001B[0m     h5file\u001B[38;5;241m.\u001B[39mcreate_dataset(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m, data\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39mlabels)\n",
      "File \u001B[1;32m~\\Workplace\\PyTorchPlayground\\venv\\Lib\\site-packages\\h5py\\_hl\\group.py:183\u001B[0m, in \u001B[0;36mGroup.create_dataset\u001B[1;34m(self, name, shape, dtype, data, **kwds)\u001B[0m\n\u001B[0;32m    181\u001B[0m         group \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequire_group(parent_path)\n\u001B[1;32m--> 183\u001B[0m dsid \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_new_dset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    184\u001B[0m dset \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mDataset(dsid)\n",
      "File \u001B[1;32m~\\Workplace\\PyTorchPlayground\\venv\\Lib\\site-packages\\h5py\\_hl\\dataset.py:166\u001B[0m, in \u001B[0;36mmake_new_dset\u001B[1;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001B[0m\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, Empty)):\n\u001B[1;32m--> 166\u001B[0m     \u001B[43mdset_id\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mh5s\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mALL\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh5s\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mALL\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dset_id\n",
      "File \u001B[1;32mh5py\\_objects.pyx:54\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\_objects.pyx:55\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\h5d.pyx:282\u001B[0m, in \u001B[0;36mh5py.h5d.DatasetID.write\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\_proxy.pyx:115\u001B[0m, in \u001B[0;36mh5py._proxy.dset_rw\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mOSError\u001B[0m: [Errno 28] Can't synchronously write data (file write failed: time = Wed Oct 18 01:55:50 2023\n, filename = 'game_data\\player_count=2\\board_size=4\\game_length=400\\name=naive_simulation\\version=0005\\data.h5', file descriptor = 3, errno = 28, error message = 'No space left on device', buf = 0000034601000100, total write size = 774400000, bytes this sub-write = 774400000, bytes actually written = 18446744073709551615, offset = 2048)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 37\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSaving dataset: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mversion\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m04\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     36\u001B[0m catalog \u001B[38;5;241m=\u001B[39m DataCatalog(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgame_data\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 37\u001B[0m \u001B[43mcatalog\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\dakot\\workplace\\pytorchplayground\\venv\\src\\chinese-checkers\\src\\chinese_checkers\\simulation\\DataCatalog.py:57\u001B[0m, in \u001B[0;36mDataCatalog.save_dataset\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m     48\u001B[0m dataset_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_construct_path(\n\u001B[0;32m     49\u001B[0m     dataset\u001B[38;5;241m.\u001B[39mplayer_count,\n\u001B[0;32m     50\u001B[0m     dataset\u001B[38;5;241m.\u001B[39mboard_size,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     53\u001B[0m     dataset\u001B[38;5;241m.\u001B[39mversion\n\u001B[0;32m     54\u001B[0m )\n\u001B[0;32m     55\u001B[0m dataset_path\u001B[38;5;241m.\u001B[39mmkdir(parents\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 57\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mh5py\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_path\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFILENAME\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mw\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mas\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mh5file\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m     58\u001B[0m \u001B[43m    \u001B[49m\u001B[43mh5file\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     59\u001B[0m \u001B[43m    \u001B[49m\u001B[43mh5file\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlabels\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mh5py\\_objects.pyx:54\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\_objects.pyx:55\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Workplace\\PyTorchPlayground\\venv\\Lib\\site-packages\\h5py\\_hl\\files.py:599\u001B[0m, in \u001B[0;36mFile.__exit__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    596\u001B[0m \u001B[38;5;129m@with_phil\u001B[39m\n\u001B[0;32m    597\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__exit__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m    598\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mid:\n\u001B[1;32m--> 599\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclose\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Workplace\\PyTorchPlayground\\venv\\Lib\\site-packages\\h5py\\_hl\\files.py:581\u001B[0m, in \u001B[0;36mFile.close\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    575\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mid\u001B[38;5;241m.\u001B[39mvalid:\n\u001B[0;32m    576\u001B[0m     \u001B[38;5;66;03m# We have to explicitly murder all open objects related to the file\u001B[39;00m\n\u001B[0;32m    577\u001B[0m \n\u001B[0;32m    578\u001B[0m     \u001B[38;5;66;03m# Close file-resident objects first, then the files.\u001B[39;00m\n\u001B[0;32m    579\u001B[0m     \u001B[38;5;66;03m# Otherwise we get errors in MPI mode.\u001B[39;00m\n\u001B[0;32m    580\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mid\u001B[38;5;241m.\u001B[39m_close_open_objects(h5f\u001B[38;5;241m.\u001B[39mOBJ_LOCAL \u001B[38;5;241m|\u001B[39m \u001B[38;5;241m~\u001B[39mh5f\u001B[38;5;241m.\u001B[39mOBJ_FILE)\n\u001B[1;32m--> 581\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_close_open_objects\u001B[49m\u001B[43m(\u001B[49m\u001B[43mh5f\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mOBJ_LOCAL\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m|\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mh5f\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mOBJ_FILE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    583\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mid\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m    584\u001B[0m     _objects\u001B[38;5;241m.\u001B[39mnonlocal_close()\n",
      "File \u001B[1;32mh5py\\_objects.pyx:54\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\_objects.pyx:55\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\h5f.pyx:355\u001B[0m, in \u001B[0;36mh5py.h5f.FileID._close_open_objects\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Can't decrement id ref count (unable to extend file properly)"
     ]
    }
   ],
   "source": [
    "for version in range(100):\n",
    "    print(f\"Generating data for version: {version:04}\")\n",
    "    simulated_games = []\n",
    "    labels = []\n",
    "    draw_count = 0\n",
    "    while len(simulated_games) < 1000:\n",
    "        max_turns = 400\n",
    "        simulation = GameSimulation([CentroidModel(), CentroidModel()], max_turns=max_turns)\n",
    "        try:\n",
    "            winner = simulation.simulate_game()\n",
    "            simulated_games.append(simulation.tensor(max_turns))\n",
    "            labels.append(0 if winner.player_id == 'Player 0' else 1)\n",
    "\n",
    "        except Exception as e:\n",
    "            draw_count += 1\n",
    "            continue\n",
    "\n",
    "    print(f\"Draws: {draw_count}\")\n",
    "    percent = lambda c : round(c/len(labels)*100, 4)\n",
    "    print(f\"Player 0 wins: {labels.count(0)} ({percent(labels.count(0))}%)\")\n",
    "    print(f\"Player 1 wins: {labels.count(1)} ({percent(labels.count(1))}%)\")\n",
    "\n",
    "    dataset = SimulationDataSet(\n",
    "        player_count=2,\n",
    "        board_size=4,\n",
    "        game_length=max_turns,\n",
    "        name=\"naive_simulation\",\n",
    "        version=f\"{version:04}\",\n",
    "        description=\"Naive simulation of games using centroid model.\",\n",
    "        data=stack(simulated_games),\n",
    "        labels=tensor(labels)\n",
    "    )\n",
    "\n",
    "    print(f\"Saving dataset: {version:04}\")\n",
    "\n",
    "    catalog = DataCatalog(\"game_data\")\n",
    "    catalog.save_dataset(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T08:55:51.171393500Z",
     "start_time": "2023-10-18T06:37:56.178156300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'player_count': '2',\n  'board_size': '4',\n  'game_length': '400',\n  'name': 'naive_simulation',\n  'version': '0000'},\n {'player_count': '2',\n  'board_size': '4',\n  'game_length': '400',\n  'name': 'naive_simulation',\n  'version': '0001'},\n {'player_count': '2',\n  'board_size': '4',\n  'game_length': '400',\n  'name': 'naive_simulation',\n  'version': '0002'},\n {'player_count': '2',\n  'board_size': '4',\n  'game_length': '400',\n  'name': 'naive_simulation',\n  'version': '0003'},\n {'player_count': '2',\n  'board_size': '4',\n  'game_length': '400',\n  'name': 'naive_simulation',\n  'version': '0004'},\n {'player_count': '2',\n  'board_size': '4',\n  'game_length': '400',\n  'name': 'naive_simulation',\n  'version': '0005'}]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.list_datasets()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T00:55:45.403997400Z",
     "start_time": "2023-10-19T00:55:45.382751Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1000, 400, 2, 121])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "1000"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = catalog.get_dataset(\n",
    "    player_count=2,\n",
    "    board_size=4,\n",
    "    game_length=400,\n",
    "    name=\"naive_simulation\",\n",
    "    version=\"0002\"\n",
    ")\n",
    "display(tensor(dataset.data).size())\n",
    "len(dataset.labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T00:55:55.175936200Z",
     "start_time": "2023-10-19T00:55:54.351197Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Data Storage Size Optimization\n",
    "Given we could only store a small handful of simulated games, we need to rethink our approach to data storage. We'll begin by exploring the size of our data on disk."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of directory 'game_data': 3.61 GB\n"
     ]
    }
   ],
   "source": [
    "def get_directory_size(path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            total_size += os.path.getsize(file_path)\n",
    "\n",
    "    return total_size\n",
    "\n",
    "def human_readable_size(size, decimal_places=2):\n",
    "    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if size < 1024.0:\n",
    "            break\n",
    "        size /= 1024.0\n",
    "    return f\"{size:.{decimal_places}f} {unit}\"\n",
    "\n",
    "directory_path = \"game_data\"\n",
    "total_size = get_directory_size(directory_path)\n",
    "print(f\"Total size of directory '{directory_path}': {human_readable_size(total_size)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T00:58:01.494880600Z",
     "start_time": "2023-10-19T00:58:01.472956900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "lol okay, so maybe I need to clear up some space on my hard drive. But, I think we can do better than this. Let's see how much space we can save by compressing our data.  All the padded zeros are probably a good candidate for compression.  We can simply store the game state in its raw form with player ids and their occupied positions.  The tensors can be reconstructed from this data when loaded.  I think a PyTorch DataLoader or Dataset can handle this for us.\n",
    "```python\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
