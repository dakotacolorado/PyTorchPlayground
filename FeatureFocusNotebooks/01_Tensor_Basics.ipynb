{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1 Tensor Basics\n",
    "**Objective:** Learn the basics of PyTorchâ€™s Tensor library."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T18:15:29.687414100Z",
     "start_time": "2023-10-14T18:15:29.672629500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 1.1 Understanding Tensors\n",
    "### Creating Tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2, 3],\n        [4, 5, 6]])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "torch.Size([2, 3])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a tensor from a list\n",
    "tensor_from_list = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Display the tensor\n",
    "display(tensor_from_list)\n",
    "display(tensor_from_list.size())\n",
    "\n",
    "# Create a tensor of zeros with size 2x3\n",
    "zero_tensor = torch.zeros(2, 3)\n",
    "\n",
    "# Create a tensor of ones with size 2x3\n",
    "ones_tensor = torch.ones(2, 3)\n",
    "\n",
    "# Create a tensor with random values of size 2x3\n",
    "rand_tensor = torch.rand(2, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T18:15:31.970944300Z",
     "start_time": "2023-10-14T18:15:31.943447600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tensor Operations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Addition\n",
    "sum_tensor = tensor_from_list + ones_tensor\n",
    "\n",
    "# Subtraction\n",
    "diff_tensor = tensor_from_list - ones_tensor\n",
    "\n",
    "# Multiplication (element-wise)\n",
    "product_tensor = tensor_from_list * ones_tensor\n",
    "\n",
    "# Division (element-wise)\n",
    "quotient_tensor = tensor_from_list / ones_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T18:15:33.704583100Z",
     "start_time": "2023-10-14T18:15:33.680774700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 1.2 Basic Operations in PyTorch\n",
    "\n",
    "### Reshaping Tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2],\n        [3, 4],\n        [5, 6]])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "torch.Size([3, 2])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshape a tensor to 3x2\n",
    "reshaped_tensor = tensor_from_list.view(3, 2)\n",
    "display(reshaped_tensor)\n",
    "display(reshaped_tensor.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T18:13:00.238986800Z",
     "start_time": "2023-10-14T18:13:00.093723700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Concatenating Tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 2., 3.],\n        [4., 5., 6.],\n        [1., 1., 1.],\n        [1., 1., 1.]])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "torch.Size([4, 3])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenate tensors along a given dimension\n",
    "concatenated_tensor = torch.cat((tensor_from_list, ones_tensor), dim=0)\n",
    "display(concatenated_tensor)\n",
    "display(concatenated_tensor.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T18:13:36.997159800Z",
     "start_time": "2023-10-14T18:13:36.982552Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Slicing Tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 2, 3])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "torch.Size([3])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Slice tensor to get the first row\n",
    "first_row = tensor_from_list[0, :]\n",
    "display(first_row)\n",
    "display(first_row.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T18:14:07.385069600Z",
     "start_time": "2023-10-14T18:14:07.355646600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 1.3 Autograd: Automatic Differentiation\n",
    "PyTorch provides automatic differentiation for all operations on Tensors. This is essential for training neural networks.\n",
    "\n",
    "#### Using Autograd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1.],\n        [1., 1.]])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a tensor and set requires_grad=True to track computation with it\n",
    "x = torch.tensor([[1.0, 2.0], [3.0, 4.0]], requires_grad=True)\n",
    "\n",
    "# Define a simple operation\n",
    "y = x + 2\n",
    "\n",
    "# Compute gradients\n",
    "y.backward(torch.ones_like(x))\n",
    "\n",
    "# The gradients w.r.t x are now stored in x.grad\n",
    "display(x.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T18:16:26.195711Z",
     "start_time": "2023-10-14T18:16:26.179696800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Differentiation in Autograd\n",
    "\n",
    "### Gradients from Partial Derivatives\n",
    "Consider the function $f(x, y) = (x + y) \\cdot (x - y) = x^2 + y^2 - xy$. We will calculate the partial derivatives of $f$ with respect to $x$ and $y$ and evaluate them at the point $(x=2, y=3)$.\n",
    "\n",
    "The function $f(x, y)$ is defined as:\n",
    "\n",
    "$$\n",
    "f(x, y) = x^2 + y^2 - xy\n",
    "$$\n",
    "\n",
    "1. The partial derivative of $f$ with respect to $y$, denoted as $\\frac{\\partial f}{\\partial y}$, is given by:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial y} = 2y - x\n",
    "$$\n",
    "\n",
    "2. The partial derivative of $f$ with respect to $x$, denoted as $\\frac{\\partial f}{\\partial x}$, is given by:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x} = 2x - y\n",
    "$$\n",
    "\n",
    "Now, let's evaluate these partial derivatives at the point $(x=2, y=3)$:\n",
    "\n",
    "1. The partial derivative $\\frac{\\partial f}{\\partial y}$ at $(x=2, y=3)$ is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial y}\\Bigg|_{x=2, y=3} = 2(3) - 2 = 6 - 2 = 4\n",
    "$$\n",
    "\n",
    "2. The partial derivative $\\frac{\\partial f}{\\partial x}$ at $(x=2, y=3)$ is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x}\\Bigg|_{x=2, y=3} = 2(2) - 3 = 4 - 3 = 1\n",
    "$$\n",
    "\n",
    "So, at the point $(x=2, y=3)$, the partial derivative of $f$ with respect to $y$ is 4, and the partial derivative with respect to $x$ is 1.\n",
    "\n",
    "### Gradients with Autograd\n",
    "\n",
    "In autograd it will apply derivatives recursively on each variable it tracks using the chain rule. This leads to an interesting difference in results when compared to the partial derivatives calculated above.  In the factorized version it gives different results than when in the expanded version. This is because the chain rule is applied differently in each case."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(2., requires_grad=True)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tensor(3., requires_grad=True)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the variables x and y, and set requires_grad=True to track computations\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = torch.tensor(3.0, requires_grad=True)\n",
    "display(x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T18:45:12.850810800Z",
     "start_time": "2023-10-14T18:45:12.832457300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of f w.r.t x: 4.0\n",
      "Gradient of f w.r.t y: -6.0\n"
     ]
    }
   ],
   "source": [
    "# Define the function in factorized form\n",
    "f = (x + y) * (x - y)\n",
    "\n",
    "# Compute the gradients\n",
    "f.backward()\n",
    "\n",
    "# Notice the gradients are different than the partial derivatives\n",
    "print(f'Gradient of f w.r.t x: {x.grad.item()}')\n",
    "print(f'Gradient of f w.r.t y: {y.grad.item()}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T18:45:13.116584100Z",
     "start_time": "2023-10-14T18:45:13.096436100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(2., requires_grad=True)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tensor(3., requires_grad=True)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of f w.r.t x: 1.0\n",
      "Gradient of f w.r.t y: 4.0\n"
     ]
    }
   ],
   "source": [
    "# Define the function in expanded form\n",
    "f = (x ** 2) + (y ** 2) - (x * y)\n",
    "\n",
    "# Compute the gradients\n",
    "f.backward()\n",
    "\n",
    "# Notice the gradients are consistent with the partial derivatives\n",
    "print(f'Gradient of f w.r.t x: {x.grad.item()}')  # Output: Gradient of f w.r.t x: 4.0\n",
    "print(f'Gradient of f w.r.t y: {y.grad.item()}')  # Output: Gradient of f w.r.t y: -6.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T18:39:31.203840800Z",
     "start_time": "2023-10-14T18:39:31.175454100Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
